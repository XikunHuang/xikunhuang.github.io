---
title: MLAPP笔记-离散数据生成模型
date: 2018-11-28
categories:
    - 技术
tags:
    - MLAPP
    - 机器学习
mathjax: true
---

## 简介

先来说一下**生成式模型(generative models)** 和 **判别式模型(discriminative models)**.

对于分类问题, 我们的目标是基于有限的训练样本集尽可能准确地估计出后验概率$p(c\vert x)$, 而估计该后验概率有两种方式:

- 判别式模型: 直接建模$p(c \vert x)$.
- 生成式模型: 先对联合分布$p(x,c)$建模, 再由此得到$p(c \vert x)$.

本章着眼于生成式模型, 由贝叶斯定理可得 $$p(c\vert x)=\frac{p(x\vert c)p(c)}{p(x)}$$

所以问题关键就在于求得

- 类条件概率分布(class-conditional density)  $p(x\vert c)$
- 先验分布 $p(c)$

## 概率分布

继续进行之前, 这里先罗列一下本章涉及的一些概率分布.

### 伯努利分布和二项分布

可用来建模掷硬币的结果

- 伯努利分布

  $$X \sim Ber(\theta)$$ $$Ber(x\vert \theta) = \theta^{\mathbb{I}(x=1)}(1-\theta)^{\mathbb{I}(x=0)}$$

  即随机变量$X \in \{0,1\}$, 且 $$p(X=1) = \theta$$ $$p(X=0) = 1 - \theta$$

- 二项分布

  $$X \sim Bin(n,\theta)$$  $$Bin(k\vert n,\theta) = \binom{n}{k} \theta^k (1-\theta)^{n-k} $$

  即随机变量$X \in \{0,\dots, n\}$, 且 $$p(X=k) =  \binom{n}{k} \theta^k (1-\theta)^{n-k}$$

### 多伯努利分布和多项分布

可用来建模掷具有$K$面的骰子的结果

- 多伯努利分布

    $$X \sim Cat(\theta)$$  $$Cat(x\vert \theta) = \prod_{j=1}^K \theta_j^{\mathbb{I}(x_j=1)}$$

    $X$取值为$K$维one-hot编码.

- 多项分布

    $$X \sim Mu(n, \theta)$$  $$Mu(x\vert n,\theta) = \binom{n}{x_1 \dots x_K} \prod_{j=1}^K \theta_j^k$$

    $X$是K维向量, 且满足 $$x_k\in\{0,\dots,n\}$$ $$\sum_{k=1}^Kx_k = n$$

### 贝塔分布和狄利克雷分布

- 贝塔分布

    $$X \sim Beta(a,b)$$  $$Beta(x\vert a,b) = \frac{1}{B(a,b)}x^{a-1}(1-x)^{b-1}$$

    $X$取值范围是$[0,1]$. 要求$a,b>0$.
    当$a=b=1$时退化为$[0,1]$上的均匀分布.

- 狄利克雷分布

    贝塔分布的多元扩展, 相当于考虑的是多个随机变量的联合分布.

    $$X \sim Dir(\alpha_1,\dots, \alpha_k)$$  $$Dir(x\vert \alpha_1,\dots,\alpha_k) = \frac{1}{B(\alpha_1,\dots,\alpha_k)}\prod_{k=1}^K x_k^{\alpha_k - 1} \mathbb{I}(x\in S_K)$$

    其中$$ S_K = \{x:0\leq x_k \leq 1, \sum_{k=1}^K x_k = 1\}$$

    狄利克雷分布在$S_K$以外的地方概率为$0$.

## 贝叶斯概念学习

类比于小孩子学习理解单词的含义, 概念学习可以等价于二分类问题, 即学习一个函数$f(x)$, 如果$x$是概念$C$的一个实例, 则$f(x)=1$, 否则$f(x)=0$.
一般处理二分类问题时会从正例和反例中同时学习, 但本小节介绍的例子只从正例中学习.

### 数字游戏

首先我会选择一个范围在$[1,100]$的整数代数概念$C$(不会告诉你), 比如质数, $1$到$10$之间的数等等. 然后我会告诉你数字$\mathcal{D}=\{x_1,\dots,x_N\}$是从概念$C$中随机挑选出来的. 比如假设我之前选的概念$C$是奇数, 那么我可能告诉你$\{3,17,5,97\}$这些数字. 然后接下来问你一些新的数字$\tilde{x}$是否属于概念$C$. 其实就是让你在给定一些正例的情况下猜测我之前设定的概念$C$是什么.

比如告诉你 $\{2,4,8,16,32\}$ 这些数字属于概念$C$, 那么问你$62$属于概念$C$吗? 我们基于这些数字可能会猜测概念$C$大概率是$2^n$, 所以判断$62$不属于概念$C$. 那么如果再告诉你$30$也属于概念$C$, 那么现在你觉得$62$属于概念$C$吗? 这时候我们就可能认为概念$C$是偶数吧, 然后判断$62$属于概念$C$.

怎么来解释和模拟上述行为呢? 一种方法是用假设空间(hypothesis space)和版本空间(version space). 最开始我们对概念$C$有一个假设空间$\mathcal{H}$, 比如质数, 奇数, $10$的倍数等等. 然后当我们看到一些正例时, 那些符合正例的概念构成的$\mathcal{H}$的子集就是版本空间. 随着我们看到的正例越多, 版本空间会越来越小(至少不会增大), 表示着我们离正确概念越来越近(如果假设空间包含正确概念的话). 以上面的例子为例, 当我们看到$\{2,4,8,16,32,128\}$时, 偶数, $2^n$等等这些概念都在版本空间中, 质数等概念不在版本空间中, 当我们又看到$30$时, 概念$2^n$也从版本空间中删除.

另外一个问题是我们看到$\{2,4,8,16,32,128\}$时, 其实$2^n$和偶数都在版本空间中,那么我们为什么会倾向于$2^n$呢?

### 似然

对于上小节最后一个问题, 直观想法是我们想避免 suspicious coincidence. 即如果概念$C$是偶数, 那么为什么那么巧我们看到的数都符合$2^n$.
下面从概率角度解释一下.
我们假定看到的数字是从概念$C$中均匀随机选取的. 我们引入似然 $p(\mathcal{D}\vert h)$, 则

$$p(\{2\}\vert h_{2^n}) = \frac{1}{6} $$

因为在$[1,100]$整数中只有$6$个整数满足$2^n$. 而

$$p(\{2\}\vert h_{even}) = \frac{1}{50}$$

同理可以计算$$p(\{2,4,8,16,32\}\vert h_{2^n}) \gg p(\{2,4,8,16,32\}\vert h_{even})$$
这就解释了我们为什么会倾向于$2^n$(这里默认了不同概念先验概率相等).

### 先验

还是上面的例子, 看到$\{2,4,8,16,32\}$这些数, 概念"满足$2^n$且不是$64$"比$2^n$更符合数据, 但是前一个怪怪的不自然, 我们可以给这种概念赋予较小的先验概率, 即
$$p(C=h_{2^n且不包含64}) < p(C=h_{2^n})$$

### 后验

后验概率正比于似然乘上先验, 即
$$p(h\vert \mathcal{D}) \propto p(\mathcal{D}\vert h)p(h) $$
当数据量比较多时, 后验概率在某个概念上值比较大, 这个概念就是所谓的**最大后验概率估计(MAP)**. 即
$$\hat{h}^{MAP} = \arg\max_h \ \ p(h\vert \mathcal{D})$$
由贝叶斯公式,上式可以写成
$$\hat{h}^{MAP} = \arg\max_h \ \ p(\mathcal{D}\vert h)p(h) = \arg\max_h \ \ [\log p(\mathcal{D}\vert h) + \log p(h)] $$
似然项会变(指数依赖样本大小$N$), 而先验项保持不变. 当数据量变大时, MAP趋向于**最大似然估计(MLE)**.
$$\hat{h}^{MLE} = \arg\max_h \ \ p(\mathcal{D}\vert h) = \arg\max_h \ \ \log p(\mathcal{D}\vert h)$$
换句话说, 当我们有足够数据量时, 数据会忽略掉先验. MAP会收敛到MLE.

### 后验预测分布

我们得到的后验概率分布是在观测到现有数据的条件下,假设空间中那些概念是实际概念的概率. 但是现在给我们一个新的数字$\tilde{x}$, 我们怎么决策它是否属于实际概念$C$呢? 这就是后验预测分布干的活.
这种情形下的后验预测分布为
$$p(\tilde{x} \in C \vert  \mathcal{D}) = \sum_h p(y=1\vert \tilde{x},h) p(h\vert \mathcal{D})$$
本质上就是对假设空间中的概念的预测结果做一个加权平均, 权重就是概念对应的后验概率. 这个成为**贝叶斯模型平均(Bayes model averaging)**.

当数据量很小时,可能后验概率分布很广泛. 但是当数据量很多, 多到几乎"暴露"出真实概念时, 这个时候后验概率会集中在最大后验概率的那个概念上. 这时候后验预测分布就可以近似为
$$p(\tilde{x} \in C \vert  \mathcal{D}) = p(\tilde{x}\vert \hat{h}^{MAP})$$
这个被称为预测分布的**plug-in approximation**.

#### BMA vs Plug-in Approximation

随着数据的增多

- BMA由宽到窄.
- Plug-in Approximation由窄到宽.

啥意思呢? 就是比如我们上来只看到一个数据$\{16\}$, 这时候给你一个$\tilde{x}=8$问你属不属于概念$C$.  BMA这时候一脸懵逼不敢妄下断言, 很多概念的后验概率都非零, 而且没有某个概念后验概率很大, 它的标准放得很宽,更有可能回答是. 但是Plug-in Approximation就不一样了, 它上来就从假设空间中挑一个最大化后验概率的那个概念(假设挑出的是$4^n$), 那么它的回答就是否. 但是如果接下来告诉我们$\{2,4,64\}$也是正例, 这时候$2^n$对应的后验概率可能大于其他概念, 那BMA会进行相应的调整, 收窄自己的标准, 而Plug-in Approximation也会调整(假设就调整成了$2^n$), 相比于$4^n$, 它是放宽了自己的标准. 虽然在数据量比较小时两种方法会有偏差, 但当数据量很大时, 两种方法收敛到相同的标准.

## The beta-binomial model

本小节讨论给定一系列观察到的掷硬币的结果, 预测下一次掷硬币出现正面的概率. 叙述方式与上一节相同
似然 -> 先验 -> 后验 -> 后验预测

### 似然

假设 $X_i \sim Ber(\theta)$, 其中$X_i=1$表示正面, $X_i=0$表示反面, $\theta \in [0,1]$是参数(表示正面的概率). 如果数据 iid, 那么似然为
$$p(\mathcal{D}\vert \theta) = \theta^{N_1}(1-\theta)^{N_0}$$
实际上是一个二项分布.
> 注: 这里的每一个$\theta$对应的伯努利分布就相当于上节中的假设空间中的一个概念$h$.

### 先验

我们要给$\theta$一个先验分布, $\theta$取值范围为$[0,1]$, 表示我们在观察数据之前对$\theta$的认识. 如果先验分布和上节的似然具有相同的形式, 那么数学上计算会很方便.
综上两点, Beta分布当仁不让.
$$Beta(\theta\vert a,b) \propto \theta^{a-1}(1-\theta)^{b-1}$$
此时后验分布具有和先验分布相同的形式.
同时先验中的$a,b$是超参数, 需要我们自己设定, $a,b$的取值融合了我们对$\theta$的认识, 比如我们认为$\theta$具有均值$0.7$, 方差$0.2$, 那么我们就可以设置为$a=2.975,b=1.275$. 或者我们对$\theta$一无所知, 那我们可以设置为均匀分布$a=b=1$.

> **共轭先验**: 如果先验分布和似然函数可以使得先验分布和后验分布有相同的形式，那么就称先验分布与似然函数是共轭的，共轭的结局是让先验与后验具有相同的形式.
再强调一遍, 共轭先验指的是对于似然来说这个先验是共轭先验.

### 后验

后验概率分布为
$$p(\theta\vert \mathcal{D}) \propto Bin(N_1\vert \theta, N_0+N_1)\ Beta(\theta\vert a,b) \propto Beta(\theta\vert N_1+a, N_0+b)$$
由Beta分布的性质(mode的表达式)可得
$$\hat{\theta}_{MAP} = \frac{a+N_1-1}{a+b+N_0+N_1-2}$$
如果先验为均匀分布($a=b=1$), 则上式退化为
$$\hat{\theta}_{MLE} = \frac{N_1}{N_0+N_1}$$
后验概率分布的均值为
$$\bar{\theta} = \frac{a+N_1}{a+b+N_0+N_1}$$
进一步可以证明, **后验概率分布的均值是先验均分布的均值和最大似然估计的凸组合**. 即
$$\mathbb{E}[\theta\vert \mathcal{D}] = \lambda \frac{a}{a+b} + (1-\lambda)\hat{\theta}_{MLE}$$
也就是说, 后验是我们观察数据之前相信的知识和数据想要告诉我们的知识的一个折中.

### 后验预测分布

当我们有了后验概率分布$Beta(c,d)$后, 我们要预测下一次掷硬币是正面的概率.
$$p(\tilde{x}=1\vert \mathcal{D}) = \int_0^1 p(x=1\vert \theta)p(\theta\vert \mathcal{D})d\theta$$
即把$\theta$当成随机变量看待, 对$\theta$所有可能情况进行汇总.
带入 $p(x=1\vert \theta)=\theta$, $p(\theta\vert \mathcal{D})=Beta(\theta\vert c,d)$可得
$$p(\tilde{x}=1\vert \mathcal{D}) = \int_0^1\theta Beta(\theta\vert c,d) d\theta = \mathbb{E}[\theta\vert \mathcal{D}] = \frac{c}{c+d}$$
即在这个例子中我们有 $$p(\tilde{x}\vert \mathcal{D})=Ber(\tilde{x}\vert \mathbb{E}[\theta\vert \mathcal{D}])$$

#### 过拟合问题

如果我们在预测时不使用上面的BMA, 而是使用
$$p(\tilde{x}\vert \mathcal{D})=Ber(\tilde{x}\vert \hat{\theta}_{MLE})$$
即
$$p(\tilde{x}=1\vert \mathcal{D}) = \hat{\theta}_{MLE} = \frac{N_1}{N_0+N_1} $$
在数据集比较小时, 这非常容易过拟合, 比如样本集合为$3$次观测结果,且全是反面, 那么根据最大似然估计
$$p(\tilde{x}=1\vert \mathcal{D}) = \hat{\theta}_{MLE} = \frac{N_1}{N_0+N_1} = 0 $$
而贝叶斯方法可以很好的克服这个问题, 比如我们假定先验分布为均匀分布$a=b=1$, 那么根据后验预测分布我们有
$$p(\tilde{x}=1\vert \mathcal{D}) = \mathbb{E}[\theta\vert \mathcal{D}] = \frac{c}{c+d} = \frac{N_1+1}{N_0+N_1+2} = \frac{1}{5}$$
这正对应着**加一平滑**这种技巧.

## The Dirichlet-multinomial model

本小节讨论给定一系列观察到的掷具有$K$面骰子的结果, 预测下一次掷骰子出现每一面的概率. 叙述方式与上一节相同
似然 -> 先验 -> 后验 -> 后验预测

### 似然

假设数据 iid, 那么似然为
$$p(\mathcal{D}\vert \theta) = \prod_{i=1}^K \theta_k^{N_k}$$
实际上是一个多项分布.

### 先验

选取先验时我们主要考虑两点, 一是参数$\theta$取值范围, 另一个是希望先验对于似然来说是共轭先验. Dirichlet分布满足这两个条件.
$$Dir(\theta\vert \alpha_1,\dots,\alpha_K) = \frac{1}{B(\alpha_1,\dots,\alpha_K)}\prod_{k=1}^K \theta_k^ {\alpha_k-1}\mathbb{I}(\theta \in S_K)$$

### 后验

后验概率分布依然是Dirichlet分布
$$p(\theta\vert \mathcal{D}) \propto p(\mathcal{D}\vert \theta)p(\theta) = Dir(\theta \vert  \alpha_1+N_1,\dots, \alpha_K+N_K)$$

后验概率分布的MAP估计是
$$\hat{\theta}_k^{MAP} = \frac{N_k+\alpha_k-1}{N_1+\dots+N_k+\alpha_1+\dots+\alpha_K-K}$$
当先验分布退化为均匀分布时,MAP退化为MLE
$$\hat{\theta}_k^{MAP} = \frac{N_k}{N_1+\dots+N_k}$$

### 后验预测分布

预测下一次掷骰子出现每一面的概率
$$
\begin{eqnarray}
p(X=j\vert \mathcal{D}) &=& \int p(X=j\vert \theta)p(\theta\vert \mathcal{D})d\theta \\
&=& \frac{\alpha_j+N_j}{\alpha_1+\dots+\alpha_K + N_1+\dots+N_K}
\end{eqnarray}
$$

## 朴素贝叶斯

朴素贝叶斯可以用来解决$K$分类问题.
问题定义: $X \in \mathbb{R}^D$, $Y \in \{1, \dots, K\}$. 给定数据集$\mathcal{D}=\{(X_1,Y_1),\dots, (X_n,Y_n)\}$, 给新的样本数据$X$分类,即求
$$p(Y\vert X,\mathcal{D})$$
我们可以利用贝叶斯公式,分别求出$p(X\vert Y,\mathcal{D})$和$p(Y)$. 但是求解$p(X\vert Y,\mathcal{D})$复杂度太高, 比如假设$X$的每一维取值范围为离散值,且大小为$S$, 那么$p(X\vert Y,\mathcal{D})$的参数个数将达到$KS^D$. 为了解决这个问题,朴素贝叶斯做了一个很强的假设:在给定类别的条件下, 特征之间相互独立. 即
$$p(X\vert Y=c) = \prod_{i=1}^D p(X^{(i)}\vert Y=c)$$

### Model fitting

#### 最大似然估计

对于一个样本$(X_i,Y_i)$, 似然函数为

$$
\begin{align}
p(X_i,Y_i\vert \vec{\theta}) &=& p(Y_i\vert \vec{\theta})p(X_i\vert Y_i,\vec{\theta}) \\
&=& p(Y_i\vert \vec{\theta}) \prod_{j=1}^{D} p(X_i^{(j)}\vert Y_i,\vec{\theta})
\end{align}
$$

其中$\vec{\theta} = \{\pi_1,\dots,\pi_K, \vec{\theta}_{11},\dots,\vec{\theta}_{DK}\}$, 这里$\pi_i$是针对$p(Y=i)$的参数, $\vec{\theta}_{jc}$是针对$p(X^{(j)}\vert Y=c)$的参数. $\vec{\theta}_{jc}$取决于第$j$维特征选取什么样的分布.
对于数据集$\mathcal{D}=\{(X_1,Y_1),\dots, (X_n,Y_n)\}$, 可计算似然函数为
$$
\begin{align}
p(\mathcal{D}\vert \theta) &=& \prod_{i=1}^n p(Y_i\vert \theta) \prod_{i=1}^n\prod_{j=1}^D  p(X_i^{(j)}\vert Y_i,\theta) \\
&=& \prod_{i=1}^n p(Y_i\vert \theta) \prod_{i=1}^n\prod_{j=1}^D  \prod_{c=1}^K p(X_i^{(j)}\vert \theta_{jc})^{\mathbb{I}(Y_i=c)}
\end{align}
$$
求对数可得
$$\log p(\mathcal{D}\vert \theta) = \sum_{c=1}^K N_c\log \pi_c + \sum_{j=1}^{D}\sum_{c=1}^K\sum_{i: Y_i=c}p(X_i^{(j)}\vert \theta_{jc})$$

在求解$\vec{\pi}$时, 需要带入约束$\sum\limits_{c=1}^K\pi_c=1$, 利用拉格朗日乘子法可得
$$\pi_c^{MLE} = \frac{N_c}{N_1+\dots+N_K}$$
而$\vec{\theta}_{jc}$需要知道特征分布的具体形式才可以求.

#### Bayesian naive Bayes

最大似然估计有个缺点是过拟合, 比如上面对$\pi_c$的估计, 当$N_c=0$时, $\pi_c^{MLE} = 0$. 为了解决过拟合问题, Bayes方法采用合适的先验分布, 比如我们使用下面形式的先验分布
$$p(\theta) = p(\pi)\prod_{j=1}^D\prod_{c=1}^Kp(\theta_{jc})$$
其中$\pi$使用Dirichlet分布, 如果每个特征是伯努利分布, 那我们就取$\theta_{jc}$为Beta分布. 那么后验分布为
$$p(\theta\vert \mathcal{D}) = p(\pi\vert \mathcal{D})\prod_{j=1}^D\prod_{c=1}^Kp(\theta_{jc}\vert \mathcal{D})$$

#### Using the model for prediction

最后的目标是用模型进行预测, 即计算
$$p(y=c\vert x,\mathcal{D}) \propto p(y=c\vert \mathcal{D})\prod_{j=1}^Dp(x_j\vert y=c_j,\mathcal{D})$$
按照Bayes的方法, 我们需要计算
$$p(y=c\vert x,\mathcal{D}) \propto [\int Cat(y=c\vert \pi) p(\pi\vert \mathcal{D})d\pi] \prod_{j=1}^D\int Ber(x_j\vert y=c,\vec{\theta_{jc}})p(\vec{\theta_{jc}}\vert \mathcal{D})d\vec{\theta_{jc}}$$
